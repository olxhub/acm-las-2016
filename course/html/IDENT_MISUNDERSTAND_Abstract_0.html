<h3>Poster Abstract</h3>
<p>In contrast to multiple-choice or selected response&nbsp;questions, constructed response questions can result in a&nbsp;wide variety of incorrect responses. However, constructed&nbsp;responses are richer in information. We propose a&nbsp;technique for using each student&rsquo;s constructed responses&nbsp;in order to identify a subset of their stable conceptual&nbsp;misunderstandings. Our approach is designed for courses&nbsp;with so many students that it is infeasible to interpret&nbsp;every distinct wrong answer manually. Instead, we label&nbsp;only the most frequent wrong answers with the&nbsp;misunderstandings that they indicate, then predict the&nbsp;misunderstandings associated with other wrong answers&nbsp;using statistical co-occurrence patterns. This tiered&nbsp;approach leverages a small amount of human labeling&nbsp;effort to seed an automated procedure that identifies&nbsp;misunderstandings in students. Our approach involves&nbsp;much less effort than inspecting all answers, substantially&nbsp;outperforms a baseline that does not take advantage of&nbsp;co-occurrence statistics, proves robust to different course&nbsp;sizes, and generalizes effectively across student cohorts.</p>
<h3>Link to Work in Progress</h3>
<p><a href="http://www.cs.berkeley.edu/~ksteph/papers/l_s_2016_misunderstandings.pdf" target="[object Object]">The work in progress paper can be found on my website.</a></p>